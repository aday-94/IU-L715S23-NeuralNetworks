[2023-05-02 11:16:18,569 INFO] Missing transforms field for train_1 data, set to default: [].
[2023-05-02 11:16:18,571 WARNING] Corpus train_1's weight should be given. We default it to 1 for you.
[2023-05-02 11:16:18,571 INFO] Missing transforms field for train_2 data, set to default: [].
[2023-05-02 11:16:18,572 WARNING] Corpus train_2's weight should be given. We default it to 1 for you.
[2023-05-02 11:16:18,572 INFO] Missing transforms field for test data, set to default: [].
[2023-05-02 11:16:18,572 WARNING] Corpus test's weight should be given. We default it to 1 for you.
[2023-05-02 11:16:18,572 INFO] Parsed 3 corpora from -data.
[2023-05-02 11:16:18,572 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.
[2023-05-02 11:16:18,572 INFO] Loading vocab from text file...
[2023-05-02 11:16:18,572 INFO] Loading src vocabulary from /N/u/ad7/Carbonate/tokenization_experiments/run/toke.vocab.src
[2023-05-02 11:16:18,575 INFO] Loaded src vocab has 61 tokens.
[2023-05-02 11:16:18,575 INFO] Loading tgt vocabulary from /N/u/ad7/Carbonate/tokenization_experiments/run/toke.vocab.tgt
[2023-05-02 11:16:18,576 INFO] Loaded tgt vocab has 59 tokens.
[2023-05-02 11:16:18,576 INFO] Building fields with vocab in counters...
[2023-05-02 11:16:18,576 INFO]  * tgt vocab size: 63.
[2023-05-02 11:16:18,576 INFO]  * src vocab size: 63.
[2023-05-02 11:16:18,576 INFO]  * src vocab size = 63
[2023-05-02 11:16:18,576 INFO]  * tgt vocab size = 63
[2023-05-02 11:16:18,589 INFO] Building model...
[2023-05-02 11:16:32,141 INFO] NMTModel(
  (encoder): RNNEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(63, 500, padding_idx=1)
        )
      )
    )
    (rnn): LSTM(500, 500, num_layers=2, dropout=0.3)
  )
  (decoder): InputFeedRNNDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(63, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout(p=0.3, inplace=False)
    (rnn): StackedLSTM(
      (dropout): Dropout(p=0.3, inplace=False)
      (layers): ModuleList(
        (0): LSTMCell(1000, 500)
        (1): LSTMCell(500, 500)
      )
    )
    (attn): GlobalAttention(
      (linear_in): Linear(in_features=500, out_features=500, bias=False)
      (linear_out): Linear(in_features=1000, out_features=500, bias=False)
    )
  )
  (generator): Sequential(
    (0): Linear(in_features=500, out_features=63, bias=True)
    (1): Cast()
    (2): LogSoftmax(dim=-1)
  )
)
[2023-05-02 11:16:32,142 INFO] encoder: 4039500
[2023-05-02 11:16:32,143 INFO] decoder: 5821063
[2023-05-02 11:16:32,143 INFO] * number of parameters: 9860563
[2023-05-02 11:16:32,144 INFO] Starting training on GPU: [0]
[2023-05-02 11:16:32,144 INFO] Start training loop without validation...
[2023-05-02 11:16:32,144 INFO] train_1's transforms: TransformPipe()
[2023-05-02 11:16:32,144 INFO] train_2's transforms: TransformPipe()
[2023-05-02 11:16:32,144 INFO] test's transforms: TransformPipe()
[2023-05-02 11:16:32,149 INFO] Weighted corpora loaded so far:
			* train_1: 1
[2023-05-02 11:16:32,149 INFO] Weighted corpora loaded so far:
			* train_1: 1
			* train_2: 1
[2023-05-02 11:16:32,150 INFO] Weighted corpora loaded so far:
			* train_1: 1
			* train_2: 1
			* test: 1
[2023-05-02 11:16:36,525 INFO] Step 50/ 1000; acc:   7.42; ppl: 4513.92; xent: 8.41; lr: 1.00000; 4702/4066 tok/s;      4 sec
[2023-05-02 11:16:38,709 INFO] Step 100/ 1000; acc:   8.90; ppl: 365.13; xent: 5.90; lr: 1.00000; 10391/8919 tok/s;      7 sec
[2023-05-02 11:16:39,432 INFO] Weighted corpora loaded so far:
			* train_1: 1
			* train_2: 1
			* test: 2
[2023-05-02 11:16:40,190 INFO] Step 150/ 1000; acc:   9.72; ppl: 52.86; xent: 3.97; lr: 1.00000; 10947/9545 tok/s;      8 sec
[2023-05-02 11:16:41,860 INFO] Step 200/ 1000; acc:  21.35; ppl: 17.69; xent: 2.87; lr: 1.00000; 11471/9966 tok/s;     10 sec
[2023-05-02 11:16:43,259 INFO] Step 250/ 1000; acc:  25.73; ppl: 12.88; xent: 2.56; lr: 1.00000; 12045/10477 tok/s;     11 sec
[2023-05-02 11:16:43,425 INFO] Weighted corpora loaded so far:
			* train_1: 2
			* train_2: 1
			* test: 2
[2023-05-02 11:16:44,825 INFO] Step 300/ 1000; acc:  29.84; ppl: 10.83; xent: 2.38; lr: 1.00000; 11444/9956 tok/s;     13 sec
[2023-05-02 11:16:46,281 INFO] Step 350/ 1000; acc:  32.49; ppl:  9.29; xent: 2.23; lr: 1.00000; 11833/10268 tok/s;     14 sec
[2023-05-02 11:16:47,163 INFO] Weighted corpora loaded so far:
			* train_1: 2
			* train_2: 1
			* test: 3
[2023-05-02 11:16:47,674 INFO] Step 400/ 1000; acc:  33.61; ppl:  8.78; xent: 2.17; lr: 1.00000; 11724/10263 tok/s;     16 sec
[2023-05-02 11:16:49,379 INFO] Step 450/ 1000; acc:  34.56; ppl:  8.38; xent: 2.13; lr: 1.00000; 11841/10241 tok/s;     17 sec
[2023-05-02 11:16:50,783 INFO] Step 500/ 1000; acc:  36.24; ppl:  7.87; xent: 2.06; lr: 1.00000; 12125/10480 tok/s;     19 sec
[2023-05-02 11:16:50,784 INFO] Saving checkpoint /N/u/ad7/Carbonate/tokenization_experiments/run/rnn_model_step_500.pt
[2023-05-02 11:16:51,197 INFO] Weighted corpora loaded so far:
			* train_1: 2
			* train_2: 2
			* test: 3
[2023-05-02 11:16:52,492 INFO] Step 550/ 1000; acc:  35.69; ppl:  8.12; xent: 2.09; lr: 1.00000; 10788/9373 tok/s;     20 sec
[2023-05-02 11:16:54,401 INFO] Step 600/ 1000; acc:  35.41; ppl:  7.96; xent: 2.07; lr: 1.00000; 11002/9474 tok/s;     22 sec
[2023-05-02 11:16:55,565 INFO] Weighted corpora loaded so far:
			* train_1: 2
			* train_2: 2
			* test: 4
[2023-05-02 11:16:55,568 INFO] Weighted corpora loaded so far:
			* train_1: 3
			* train_2: 2
			* test: 4
[2023-05-02 11:16:55,927 INFO] Step 650/ 1000; acc:  39.32; ppl:  7.05; xent: 1.95; lr: 1.00000; 10721/9266 tok/s;     24 sec
[2023-05-02 11:16:57,743 INFO] Step 700/ 1000; acc:  38.56; ppl:  7.40; xent: 2.00; lr: 1.00000; 11775/10162 tok/s;     26 sec
[2023-05-02 11:16:59,652 INFO] Step 750/ 1000; acc:  40.84; ppl:  6.89; xent: 1.93; lr: 1.00000; 11217/9654 tok/s;     28 sec
[2023-05-02 11:17:01,122 INFO] Step 800/ 1000; acc:  41.99; ppl:  6.40; xent: 1.86; lr: 1.00000; 11503/9987 tok/s;     29 sec
[2023-05-02 11:17:02,694 INFO] Step 850/ 1000; acc:  42.92; ppl:  6.22; xent: 1.83; lr: 1.00000; 11423/9934 tok/s;     31 sec
[2023-05-02 11:17:03,945 INFO] Weighted corpora loaded so far:
			* train_1: 3
			* train_2: 2
			* test: 5
[2023-05-02 11:17:04,060 INFO] Step 900/ 1000; acc:  43.00; ppl:  6.02; xent: 1.80; lr: 1.00000; 11554/10111 tok/s;     32 sec
[2023-05-02 11:17:05,612 INFO] Step 950/ 1000; acc:  42.29; ppl:  6.23; xent: 1.83; lr: 1.00000; 11980/10423 tok/s;     33 sec
[2023-05-02 11:17:07,182 INFO] Step 1000/ 1000; acc:  45.62; ppl:  5.67; xent: 1.73; lr: 1.00000; 11587/10054 tok/s;     35 sec
[2023-05-02 11:17:07,183 INFO] Saving checkpoint /N/u/ad7/Carbonate/tokenization_experiments/run/rnn_model_step_1000.pt
