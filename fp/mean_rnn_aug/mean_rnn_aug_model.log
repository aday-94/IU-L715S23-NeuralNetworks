[2023-05-02 21:04:22,611 INFO] Missing transforms field for train_1 data, set to default: [].
[2023-05-02 21:04:22,614 WARNING] Corpus train_1's weight should be given. We default it to 1 for you.
[2023-05-02 21:04:22,614 INFO] Missing transforms field for train_2 data, set to default: [].
[2023-05-02 21:04:22,616 WARNING] Corpus train_2's weight should be given. We default it to 1 for you.
[2023-05-02 21:04:22,616 INFO] Missing transforms field for train_aug_1 data, set to default: [].
[2023-05-02 21:04:22,616 WARNING] Corpus train_aug_1's weight should be given. We default it to 1 for you.
[2023-05-02 21:04:22,616 INFO] Missing transforms field for train_aug_2 data, set to default: [].
[2023-05-02 21:04:22,616 WARNING] Corpus train_aug_2's weight should be given. We default it to 1 for you.
[2023-05-02 21:04:22,616 INFO] Missing transforms field for test data, set to default: [].
[2023-05-02 21:04:22,617 WARNING] Corpus test's weight should be given. We default it to 1 for you.
[2023-05-02 21:04:22,617 INFO] Parsed 5 corpora from -data.
[2023-05-02 21:04:22,618 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.
[2023-05-02 21:04:22,618 INFO] Loading vocab from text file...
[2023-05-02 21:04:22,618 INFO] Loading src vocabulary from /N/u/ad7/Carbonate/tokenization_experiments/run/toke.aug.vocab.src
[2023-05-02 21:04:22,618 INFO] Loaded src vocab has 61 tokens.
[2023-05-02 21:04:22,618 INFO] Loading tgt vocabulary from /N/u/ad7/Carbonate/tokenization_experiments/run/toke.aug.vocab.tgt
[2023-05-02 21:04:22,619 INFO] Loaded tgt vocab has 59 tokens.
[2023-05-02 21:04:22,619 INFO] Building fields with vocab in counters...
[2023-05-02 21:04:22,619 INFO]  * tgt vocab size: 63.
[2023-05-02 21:04:22,619 INFO]  * src vocab size: 63.
[2023-05-02 21:04:22,619 INFO]  * src vocab size = 63
[2023-05-02 21:04:22,619 INFO]  * tgt vocab size = 63
[2023-05-02 21:04:22,631 INFO] Building model...
[2023-05-02 21:04:24,138 INFO] NMTModel(
  (encoder): MeanEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(63, 500, padding_idx=1)
        )
      )
    )
  )
  (decoder): InputFeedRNNDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(63, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout(p=0.3, inplace=False)
    (rnn): StackedLSTM(
      (dropout): Dropout(p=0.3, inplace=False)
      (layers): ModuleList(
        (0): LSTMCell(1000, 500)
        (1): LSTMCell(500, 500)
      )
    )
    (attn): GlobalAttention(
      (linear_in): Linear(in_features=500, out_features=500, bias=False)
      (linear_out): Linear(in_features=1000, out_features=500, bias=False)
    )
  )
  (generator): Sequential(
    (0): Linear(in_features=500, out_features=63, bias=True)
    (1): Cast()
    (2): LogSoftmax(dim=-1)
  )
)
[2023-05-02 21:04:24,140 INFO] encoder: 31500
[2023-05-02 21:04:24,140 INFO] decoder: 5821063
[2023-05-02 21:04:24,140 INFO] * number of parameters: 5852563
[2023-05-02 21:04:24,141 INFO] Starting training on GPU: [0]
[2023-05-02 21:04:24,141 INFO] Start training loop without validation...
[2023-05-02 21:04:24,141 INFO] train_1's transforms: TransformPipe()
[2023-05-02 21:04:24,141 INFO] train_2's transforms: TransformPipe()
[2023-05-02 21:04:24,141 INFO] train_aug_1's transforms: TransformPipe()
[2023-05-02 21:04:24,141 INFO] train_aug_2's transforms: TransformPipe()
[2023-05-02 21:04:24,141 INFO] test's transforms: TransformPipe()
[2023-05-02 21:04:24,141 INFO] Weighted corpora loaded so far:
			* train_1: 1
[2023-05-02 21:04:24,142 INFO] Weighted corpora loaded so far:
			* train_1: 1
			* train_2: 1
[2023-05-02 21:04:24,142 INFO] Weighted corpora loaded so far:
			* train_1: 1
			* train_2: 1
			* train_aug_1: 1
[2023-05-02 21:04:24,143 INFO] Weighted corpora loaded so far:
			* train_1: 1
			* train_2: 1
			* train_aug_1: 1
			* train_aug_2: 1
[2023-05-02 21:04:24,144 INFO] Weighted corpora loaded so far:
			* train_1: 1
			* train_2: 1
			* train_aug_1: 1
			* train_aug_2: 1
			* test: 1
[2023-05-02 21:04:28,243 INFO] Step 50/ 1000; acc:   8.83; ppl: 224.01; xent: 5.41; lr: 1.00000; 6175/4467 tok/s;      4 sec
[2023-05-02 21:04:31,697 INFO] Step 100/ 1000; acc:  16.18; ppl: 27.49; xent: 3.31; lr: 1.00000; 8536/5735 tok/s;      8 sec
[2023-05-02 21:04:34,645 INFO] Step 150/ 1000; acc:  24.83; ppl: 15.62; xent: 2.75; lr: 1.00000; 8485/6075 tok/s;     11 sec
[2023-05-02 21:04:36,899 INFO] Step 200/ 1000; acc:  27.60; ppl: 12.32; xent: 2.51; lr: 1.00000; 10425/6981 tok/s;     13 sec
[2023-05-02 21:04:39,181 INFO] Step 250/ 1000; acc:  30.57; ppl: 10.77; xent: 2.38; lr: 1.00000; 11066/7330 tok/s;     15 sec
[2023-05-02 21:04:39,450 INFO] Weighted corpora loaded so far:
			* train_1: 1
			* train_2: 1
			* train_aug_1: 2
			* train_aug_2: 1
			* test: 1
[2023-05-02 21:04:41,241 INFO] Step 300/ 1000; acc:  33.65; ppl:  9.25; xent: 2.22; lr: 1.00000; 11021/7549 tok/s;     17 sec
[2023-05-02 21:04:43,322 INFO] Step 350/ 1000; acc:  35.28; ppl:  8.70; xent: 2.16; lr: 1.00000; 11183/7574 tok/s;     19 sec
[2023-05-02 21:04:54,491 INFO] Weighted corpora loaded so far:
			* train_1: 1
			* train_2: 1
			* train_aug_1: 2
			* train_aug_2: 1
			* test: 2
[2023-05-02 21:04:54,499 INFO] Weighted corpora loaded so far:
			* train_1: 1
			* train_2: 1
			* train_aug_1: 2
			* train_aug_2: 2
			* test: 2
[2023-05-02 21:04:55,155 INFO] Step 400/ 1000; acc:  35.98; ppl:  8.43; xent: 2.13; lr: 1.00000; 9941/6781 tok/s;     31 sec
[2023-05-02 21:04:57,476 INFO] Step 450/ 1000; acc:  36.87; ppl:  8.33; xent: 2.12; lr: 1.00000; 10127/6643 tok/s;     33 sec
[2023-05-02 21:04:59,722 INFO] Step 500/ 1000; acc:  37.90; ppl:  8.17; xent: 2.10; lr: 1.00000; 11674/7147 tok/s;     36 sec
[2023-05-02 21:04:59,723 INFO] Saving checkpoint /N/u/ad7/Carbonate/tokenization_experiments/run/mean_rnn_aug/mean_rnn_aug_model_step_500.pt
[2023-05-02 21:05:00,386 INFO] Weighted corpora loaded so far:
			* train_1: 2
			* train_2: 1
			* train_aug_1: 2
			* train_aug_2: 2
			* test: 2
[2023-05-02 21:05:00,387 INFO] Weighted corpora loaded so far:
			* train_1: 2
			* train_2: 1
			* train_aug_1: 3
			* train_aug_2: 2
			* test: 2
[2023-05-02 21:05:02,559 INFO] Step 550/ 1000; acc:  38.44; ppl:  8.04; xent: 2.08; lr: 1.00000; 7663/5709 tok/s;     38 sec
[2023-05-02 21:05:05,484 INFO] Step 600/ 1000; acc:  38.34; ppl:  7.81; xent: 2.06; lr: 1.00000; 9753/5806 tok/s;     41 sec
[2023-05-02 21:05:09,066 INFO] Step 650/ 1000; acc:  39.48; ppl:  7.76; xent: 2.05; lr: 1.00000; 6948/4818 tok/s;     45 sec
[2023-05-02 21:05:11,210 INFO] Step 700/ 1000; acc:  42.30; ppl:  6.76; xent: 1.91; lr: 1.00000; 9915/7208 tok/s;     47 sec
[2023-05-02 21:05:13,458 INFO] Step 750/ 1000; acc:  42.63; ppl:  6.50; xent: 1.87; lr: 1.00000; 11053/7353 tok/s;     49 sec
[2023-05-02 21:05:14,267 INFO] Weighted corpora loaded so far:
			* train_1: 2
			* train_2: 1
			* train_aug_1: 3
			* train_aug_2: 2
			* test: 3
[2023-05-02 21:05:15,529 INFO] Step 800/ 1000; acc:  43.77; ppl:  6.47; xent: 1.87; lr: 1.00000; 10635/7534 tok/s;     51 sec
[2023-05-02 21:05:17,457 INFO] Step 850/ 1000; acc:  44.62; ppl:  6.16; xent: 1.82; lr: 1.00000; 12327/7756 tok/s;     53 sec
[2023-05-02 21:05:19,419 INFO] Weighted corpora loaded so far:
			* train_1: 2
			* train_2: 1
			* train_aug_1: 4
			* train_aug_2: 2
			* test: 3
[2023-05-02 21:05:19,423 INFO] Weighted corpora loaded so far:
			* train_1: 2
			* train_2: 2
			* train_aug_1: 4
			* train_aug_2: 2
			* test: 3
[2023-05-02 21:05:19,424 INFO] Weighted corpora loaded so far:
			* train_1: 2
			* train_2: 2
			* train_aug_1: 4
			* train_aug_2: 3
			* test: 3
[2023-05-02 21:05:19,566 INFO] Step 900/ 1000; acc:  44.61; ppl:  6.08; xent: 1.81; lr: 1.00000; 11613/7205 tok/s;     55 sec
[2023-05-02 21:05:21,809 INFO] Step 950/ 1000; acc:  44.73; ppl:  6.10; xent: 1.81; lr: 1.00000; 10798/7257 tok/s;     58 sec
[2023-05-02 21:05:24,410 INFO] Step 1000/ 1000; acc:  43.77; ppl:  6.41; xent: 1.86; lr: 1.00000; 10720/6935 tok/s;     60 sec
[2023-05-02 21:05:24,411 INFO] Saving checkpoint /N/u/ad7/Carbonate/tokenization_experiments/run/mean_rnn_aug/mean_rnn_aug_model_step_1000.pt
